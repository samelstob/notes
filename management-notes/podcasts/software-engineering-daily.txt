# Hadoop: Past, Present and Future with Mike Cafarella

HDFS or something like will be around for a very long time.  A distributed, 
low cost, hierarchical file system that exposes a hierarchal unix style 
interface to the user - that's going to be around for ever.

There's a handful of performance improvements you would like to ahve e.g. can 
I haz indexes.

We are seeing the slow agnosing death of Map Reduce.  People are not really 
writing Map Reduce jobs any more.

Map Reduce was envisioned as "a for loop replacement" - the use case was 
building web crawler inverted indexes.  It was not envisioned for analytics.

Objections from Stonebraker et al. "one step forward, two steps back" - in 
retrospect the need for higher language was correct

"The projects with the biggest impact have an element of system building and 
element of intellectual contribution.  If you want the biggest possible impact 
on the world you have to use both weapons.  There is always a way to figure 
out how to do it no matter what venue you are in"

Yarn

Dryad (Microsoft Research) had a very clean distinction between the 
programming model it exposed and the execution framework.

If you want a data flow that doesn't look like the traditional map reduce data 
flow (disk -> mapper -> shuffle -> reducer) if you want five loops of that in 
a row for some ML task that data flow graph can be more complicated than map 
reduce ever imagined.  Pig tends to tie itself in knots trying to do this - 
it's not the most natural way to do it.

Spark - unbelievable impact on things.  People were using MapReduce in a way 
that the MR implementation was not really keeping up with.

Spark performance is better but it's the terminal interaction that I think is 
best thing.

Could have been designed without a central coordinator?  You can a single 
node, or a group of nodes, or some kind of cooperation over the entire 
cluster.

Nowadays no one runs a single name node, but does it have to be the entire 
cluster?

# 2015/10/12 Replacing Hadoop with Joe Doliner

https://medium.com/pachyderm-data/lets-build-a-modern-hadoop-4fc160f8d74f#.3emocljp6

* A number of things are outdated about Hadoop
    - The software project is developed by a million different companies with 
      a million different goals.  You don't get this cohesive API that's 
      really fun to use.
    - From a software engineering level - they basically had to create all of 
      the distributed systems code from scratch because nothing like that 
      existed.  They have their own scheduler (Yarn), discovery service.  You 
      really want someone dedicated to making them generic and good.

* Facebook forked Hadoop six years ago and kept it closed source.  "A bunch of 
  little things that didn't quite fit their use case.  No big ideolical 
  difference about merging - just too many man hours"

* "At Airbnb - a huge number of outages from Zookeeper.  No one we could talk 
  to - no company has Zookeeper as their product.  These things never get 
  fixed and they never get really good."

* "Zookeeper is coupled to Hadoop because of they have been in close proximity 
  for a very long time - little specific things that Hadoop needs have crept 
  into Zookeeper."

* Containerising Hadoop is problematic

* Maintaining a consistent enviornment is one of the big challenges of running 
  a Hadoop cluster.  You are getting a string of emails from data scientists 
  "I just wrote this job that requires Python 2.3".  It isn't a fun job to 
  install dependencies on a 1000 machine Hadoop customer."

* HDFS Namenode - writing a bunch of small files swamps the name node

* Pachyderm File System (PFS) is a COW filesystem like git.  This allows 
  collaboration.

* A best practice in Hadoop land is to run entirely separate clusters.  
  Production and dev.  Moving things over from dev to prod is a hugely manual 
  process.

* In Hadoop it's this very internal magical thing that allows them to achieve 
  data locality.

* Hadoop uses - very different picture in each company.  Like MS Word - 
  billion features and each user uses a different 5%.

* "There are a lot more people who have the problem Hadoop solves, than there 
  are using Hadoop."

* "At Airbnb we thought we were going to setup a Hadoop cluster.  2.5 years 
  later this was a team of 20 people and we still weren't quite to the point 
  where we felt like we have it under control and it just works for us.  You 
  can't run a Hadoop cluster without this team of 20 people that basically 
  just kick it when it falls over."

* "Cloudera makes it easier, but it is still incredibly complicated.  Cloudera 
  have built a ML classifier which classifies configurations as stable or 
  unstable.  Configuring Hadoop is so incredibly complicated that there is no 
  human who understands what makes a configuration stable or unstable.  We have 
  actually had to resort to a classifier to solve that problem".

* "Cloudera definitely offers a lot of really good resources to make running 
  Hadoop easier but I don't think they are solving the fundamental problem.  
  To solve that we need a big leap forward."

* "I want you guys to become sales engineers."

* Letters of intent - removes "there is nobody in the world who has the 
  slightest bit of interest in this"

# 2016/03/15 State of Programming with Jeff Atwood

* 37 signals didn't think about deployment.  RoR didn't think about 
  deployment.  Docker allowed discourse to solve deployment problems.
    - "Went from being a support nightmare
* "Ruby virtualised awfully - like 40% performance loss"
* Stack Overflow SQL server licensing $0.5M licensing fees per year
* SQL server "optimise for unknown" (don't use stats - sounds like RBO or 
  dynamic sampling)
* "Linux is free if your time is worthless"
* "Co-location is insanely cheap"

# 2016/04/26 Azure Event Hubs and Kafka with Dan Rosanova

* DOn't want a direct dependenciy between publisher and subscriber (or 
  producer consumer) because they will have to be matched scale and speed 
  wise.

* May want to read events more than once

* EventHubs and Kafka chose not to use HTTP

* Typical message queues - every message that comes in, you acknowledge when 
  it's been read
* With EH you don't acknowledge individual messages, it's a time retention 
  buffer
* Replication between regions with ordering consistency and low latency is 
  very difficult (laws of physics)
* Load balancing in Kafka is manual, in EH it is included
* Kafka uses a proprietary protocol, EH uses AMQP
* HTTP limits what you can do with flow control and retransmission - these 
  shortcomings are bad when you get to high scale system.
* AMQP is an ISO, IEC, OASIS standard
    - Even though it can be a difficult protocol to undetand, the flow control 
      system is excellent.  It is a credit based system
* EventHubs was always designed to be a sub-second system wheras Kinesis was 
  not
* Kinesis, pay hourly rate per shard
* Google Cloud Pub-Sub - Kind of like EH, kind of like ServiceBus.  Each of 
  the big players has taken a slightly different approach to this challenge.
* Pub-Sub allows many many many subscribers.  EH is less about subscribers but 
  more about throughput.
* Azure is not Windows specific
* Polyglot cloud started with SaaS
* Microsoft is not trying to run the car business and the television business, 
  we are trying to put a platform in place that people on those industries can 
  run their platforms on.  Building a scalable highly available platform is 
  very challenging.  If we can do a little bit to alleviate the cost and pain 
  of that then we will rapidly increase the seped at which innovation happens 
  on top of that platform.
* The people on those industries are the ones who will drive innovation.  
  Until we make it easy for them to do that they have to make very risky big 
  bets.

